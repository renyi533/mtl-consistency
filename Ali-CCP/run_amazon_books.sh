set -x
rm -rf ckpt_books

i="0"
iter="10"
mkdir logs_books
wait_function () {
    sleep 10
    for job in `jobs -p`
    do
        echo $job
        wait $job || let "FAIL+=1"
    done
}
while [ $i -lt $iter ]
do
    python ./model/train.py --test_data_dir ./data/books/test --val_data_dir ./data/books/val --train_data_dir ./data/books/train --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/single_task_$i --mode training --early_stop 3 --keep_prob 0.5,0.5,0.5  --model st --task_layers 128,80 --epoch 100 > logs_books/single_task_train_$i.log 2>&1 &
    wait_function
    python ./model/train.py --test_data_dir ./data/books/test --val_data_dir ./data/books/val --train_data_dir ./data/books/train --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/single_task_$i --mode pred  --model st --task_layers 128,80 --epoch 1 --pred_file logs_books/single_task_result_$i.txt > logs_books/single_task_test_$i.log 2>&1 &
    wait_function

  for model in se sb mmoe ple snr
  do
    python ./model/train.py --test_data_dir ./data/books/test --val_data_dir ./data/books/val --train_data_dir ./data/books/train --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_dml_$i --mode training --early_stop 3 --keep_prob 0.5,0.5,0.5  --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience True --epoch 100 > logs_books/${model}_dml_train_$i.log 2>&1 &
    python ./model/train.py --test_data_dir ./data/books/test --val_data_dir ./data/books/val --train_data_dir ./data/books/train --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_dml_nostop_$i --mode training --early_stop 3 --keep_prob 0.5,0.5,0.5  --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience True --co_attention_stop_grad False --epoch 100 > logs_books/${model}_dml_nostop_train_$i.log 2>&1 &
    python ./model/train.py --test_data_dir ./data/books/test --val_data_dir ./data/books/val --train_data_dir ./data/books/train --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_$i --mode training --early_stop 3 --keep_prob 0.5,0.5,0.5  --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention False --global_experience False --epoch 100 > logs_books/${model}_train_$i.log 2>&1 &
    python ./model/train.py --test_data_dir ./data/books/test --val_data_dir ./data/books/val --train_data_dir ./data/books/train --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_attn_$i --mode training --early_stop 3 --keep_prob 0.5,0.5,0.5  --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience False --epoch 100 > logs_books/${model}_attn_train_$i.log 2>&1 &
    python ./model/train.py --test_data_dir ./data/books/test --val_data_dir ./data/books/val --train_data_dir ./data/books/train --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_attn_nostop_$i --mode training --early_stop 3 --keep_prob 0.5,0.5,0.5  --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience False --co_attention_stop_grad False --epoch 100 > logs_books/${model}_attn_nostop_train_$i.log 2>&1 &
    python ./model/train.py --test_data_dir ./data/books/test --val_data_dir ./data/books/val --train_data_dir ./data/books/train --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_global_$i --mode training --early_stop 3 --keep_prob 0.5,0.5,0.5  --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention False --global_experience True --epoch 100 > logs_books/${model}_global_train_$i.log 2>&1 &
    wait_function
    
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/test --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_dml_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience True --epoch 1 --pred_file logs_books/${model}_dml_result_$i.txt > logs_books/${model}_dml_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/test --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_dml_nostop_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience True --co_attention_stop_grad False --epoch 1 --pred_file logs_books/${model}_dml_nostop_result_$i.txt > logs_books/${model}_dml_nostop_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/test --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention False --global_experience False --epoch 1 --pred_file logs_books/${model}_result_$i.txt > logs_books/${model}_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/test --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_attn_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience False --epoch 1 --pred_file logs_books/${model}_attn_result_$i.txt > logs_books/${model}_attn_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/test --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_attn_nostop_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience False --co_attention_stop_grad False --epoch 1 --pred_file logs_books/${model}_attn_nostop_result_$i.txt > logs_books/${model}_attn_nostop_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/test --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_global_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention False --global_experience True --epoch 1 --pred_file logs_books/${model}_global_result_$i.txt > logs_books/${model}_global_test_$i.log 2>&1 & 
    wait_function

    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/train  --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_dml_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience True --epoch 1 --pred_file logs_books/${model}_dml_result_train_$i.txt > logs_books/${model}_dml_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/train  --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_dml_nostop_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience True --co_attention_stop_grad False --epoch 1 --pred_file logs_books/${model}_dml_nostop_result_train_$i.txt > logs_books/${model}_dml_nostop_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/train  --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention False --global_experience False --epoch 1 --pred_file logs_books/${model}_result_train_$i.txt > logs_books/${model}_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/train  --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_attn_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience False --epoch 1 --pred_file logs_books/${model}_attn_result_train_$i.txt > logs_books/${model}_attn_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/train  --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_attn_nostop_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience False --co_attention_stop_grad False --epoch 1 --pred_file logs_books/${model}_attn_nostop_result_train_$i.txt > logs_books/${model}_attn_nostop_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/train  --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_global_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention False --global_experience True --epoch 1 --pred_file logs_books/${model}_global_result_train_$i.txt > logs_books/${model}_global_test_$i.log 2>&1 &
    wait_function

    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/val  --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_dml_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience True --epoch 1 --pred_file logs_books/${model}_dml_result_val_$i.txt > logs_books/${model}_dml_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/val  --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_dml_nostop_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience True --co_attention_stop_grad False --epoch 1 --pred_file logs_books/${model}_dml_nostop_result_val_$i.txt > logs_books/${model}_dml_nostop_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/val --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention False --global_experience False --epoch 1 --pred_file logs_books/${model}_result_val_$i.txt > logs_books/${model}_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/val --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_attn_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience False --epoch 1 --pred_file logs_books/${model}_attn_result_val_$i.txt > logs_books/${model}_attn_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/val --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_attn_nostop_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience False --co_attention_stop_grad False --epoch 1 --pred_file logs_books/${model}_attn_nostop_result_val_$i.txt > logs_books/${model}_attn_nostop_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/val --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/${model}_global_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention False --global_experience True --epoch 1 --pred_file logs_books/${model}_global_result_val_$i.txt > logs_books/${model}_global_test_$i.log 2>&1 &
    wait_function
  done  
    
    python ./model/train.py --val_data_dir ./data/books/val --test_data_dir ./data/books/test  --train_data_dir ./data/books/train --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/aitm_$i --mode training --early_stop 3 --keep_prob 0.5,0.5,0.5  --model aitm --epoch 100 > logs_books/aitm_train_$i.log 2>&1 &
    wait_function
    python ./model/train.py --val_data_dir ./data/books/val --train_data_dir ./data/books/train --test_data_dir ./data/books/test --uniq_feature_cnt 603668,367982 --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_books/books/aitm_$i/best --mode pred --model aitm --epoch 1 --pred_file logs_books/aitm_dml_result_$i.txt > logs_books/aitm_test_$i.log 2>&1 &
    wait_function

i=$[$i+1]
done

find logs_books -type f -name "*result*" -exec awk '{s=$0};END{print FILENAME,s}' {} \; | sort

