{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5e29fb-db04-4a20-b26a-7f7cdf4ddd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from operator import add\n",
    "from pyspark import SparkContext\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import collections\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "612e3e50-ab34-46fe-bf5d-67be1e28aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_list =['Somecollegebutnodegree', 'Associatesdegree-occup/vocational', 'Bachelorsdegree(BAABBS)', 'Mastersdegree(MAMSMEngMEdMSWMBA)','Doctoratedegree(PhDEdD)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eb62492-47ef-4300-9050-cf02f3ac7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataParse(x):\n",
    "    res = []\n",
    "    info = x.split(',')\n",
    "    if len(info) != 42:\n",
    "        return res\n",
    "    for index in range(0, 42):\n",
    "        if index == 24 :\n",
    "            continue\n",
    "        term = str(index) + '_' + info[index].replace(' ', '')\n",
    "        res.append(term)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99be5c0a-d179-4d29-8538-0cde340d632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenSampleTask1(x, index_dict):\n",
    "    info = x.split(',')\n",
    "    feature_list = []\n",
    "    if len(info) != 42:\n",
    "        return None\n",
    "    for index in range(0, 41):\n",
    "        if index == 24 or index == 7:\n",
    "            continue\n",
    "        term = str(index) + '_' + info[index].replace(' ', '')\n",
    "        term_id = index_dict[term]\n",
    "        feature_list.append(term_id)\n",
    "\n",
    "    label1 = 0\n",
    "    label2 = 0\n",
    "    if info[7].replace(' ', '') == 'Nevermarried':\n",
    "        label1 = 1\n",
    "    if info[41].replace(' ', '') == '50000+.':\n",
    "        label2 = 1\n",
    "    line = str(label1) + ' ' + str(label2) + ' ' + ','.join(str(i) for i in feature_list)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3d0507-b71a-4dfe-a489-2697a4231cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenSampleTask2(x, index_dict):\n",
    "    info = x.split(',')\n",
    "    feature_list = []\n",
    "    if len(info) != 42:\n",
    "        return None\n",
    "    for index in range(0, 42):\n",
    "        if index == 4 or index == 7 or index == 24:\n",
    "            continue\n",
    "        term = str(index) + '_' + info[index].replace(' ', '')\n",
    "        term_id = index_dict[term]\n",
    "        feature_list.append(term_id)\n",
    "\n",
    "    label1 = 0\n",
    "    label2 = 0\n",
    "    if info[7].replace(' ', '') == 'Nevermarried':\n",
    "        label1 = 1\n",
    "    if info[4].replace(' ', '') in edu_list:\n",
    "        label2 = 1\n",
    "    line = str(label1) + ' ' + str(label2) + ' ' + ','.join(str(i) for i in feature_list)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "febf05a9-aff9-4aa2-b724-55fe141e5203",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SparkSession.builder.appName(\"Dataset\").getOrCreate()\n",
    "sc = ss.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d98a25e-6685-4d1c-9ef0-7d8c82f7ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path =\"mdfs://cloudhdfs/newsmainpagealgo/data/yingdu/mtl_relation/Census-Income/census-income.*\"\n",
    "train_data_path = \"mdfs://cloudhdfs/newsmainpagealgo/data/yingdu/mtl_relation/Census-Income/census-income.data\"\n",
    "test_data_path = \"mdfs://cloudhdfs/newsmainpagealgo/data/yingdu/mtl_relation/Census-Income/census-income.test\"\n",
    "save_train_task1_data= \"mdfs://cloudhdfs/newsmainpagealgo/data/yingdu/mtl_relation/data/train/task1\"\n",
    "save_test_task1_data = \"mdfs://cloudhdfs/newsmainpagealgo/data/yingdu/mtl_relation/data/test/task1\"\n",
    "save_train_task2_data = \"mdfs://cloudhdfs/newsmainpagealgo/data/yingdu/mtl_relation/data/train/task2\"\n",
    "save_test_task2_data = \"mdfs://cloudhdfs/newsmainpagealgo/data/yingdu/mtl_relation/data/test/task2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f6e77ce-507a-44ba-b428-d7575298cdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0_73', 0), ('3_0', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_hdfs = sc.textFile(dataset_path).flatMap(DataParse).filter(lambda x: x != []).distinct().zipWithIndex()\n",
    "index_hdfs.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b834a0e3-1d85-4876-8b86-fab7c0218536",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dict = index_hdfs.collectAsMap()\n",
    "be_index_dict = sc.broadcast(index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cf2597d-a073-44e0-9c48-41814f3910ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hdfs = sc.textFile(train_data_path).map(lambda x: GenSampleTask1(x, be_index_dict.value)).filter(lambda x: x is not None)\n",
    "train_hdfs.repartition(1).saveAsTextFile(save_train_task1_data)\n",
    "\n",
    "test_hdfs = sc.textFile(test_data_path).map(lambda x: GenSampleTask1(x, be_index_dict.value)).filter(lambda x: x is not None)\n",
    "test_hdfs.repartition(1).saveAsTextFile(save_test_task1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f473a35-4174-4cb4-ad37-83ac6731b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hdfs2 = sc.textFile(train_data_path).map(lambda x: GenSampleTask2(x, be_index_dict.value)).filter(lambda x: x is not None)\n",
    "train_hdfs2.repartition(1).saveAsTextFile(save_train_task2_data)\n",
    "\n",
    "test_hdfs2 = sc.textFile(test_data_path).map(lambda x: GenSampleTask2(x, be_index_dict.value)).filter(lambda x: x is not None)\n",
    "test_hdfs2.repartition(1).saveAsTextFile(save_test_task2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7fe2e7-84ce-4415-ace1-53f98159cfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "天穹-pyspark(local)",
   "language": "python",
   "name": "tq_pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
