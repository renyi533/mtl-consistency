set -x
iter="10"
wait_function () {
    sleep 10
    for job in `jobs -p`
    do
        echo $job
        wait $job || let "FAIL+=1"
    done
}

for config in electronics.192403,63001 
do 
IFS='.' read data feature_cnt <<< "${config}"
rm -rf ckpt_${data}
mkdir logs_${data}
i="0"

while [ $i -lt $iter ]
do
    python ./model/train.py --test_data_dir ./data/${data}/test --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/single_task_$i --mode training --early_stop 3 --keep_prob 0.5,0.5,0.5  --model st --task_layers 128,80 --epoch 100 > logs_${data}/single_task_train_$i.log 2>&1 &
    wait_function
    python ./model/train.py --test_data_dir ./data/${data}/test --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/single_task_$i --mode pred  --model st --task_layers 128,80 --epoch 1 --pred_file logs_${data}/single_task_result_$i.txt > logs_${data}/single_task_test_$i.log 2>&1 &
    wait_function

  for model in mssm se sb mmoe ple snr
  do
    python ./model/train.py --test_data_dir ./data/${data}/test --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_dml_$i --mode training --early_stop 3 --keep_prob 0.5,0.5,0.5  --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience True --epoch 100 > logs_${data}/${model}_dml_train_$i.log 2>&1 &
    python ./model/train.py --test_data_dir ./data/${data}/test --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_dml_nostop_$i --mode training --early_stop 3 --keep_prob 0.5,0.5,0.5  --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience True --co_attention_stop_grad False --epoch 100 > logs_${data}/${model}_dml_nostop_train_$i.log 2>&1 &
    python ./model/train.py --test_data_dir ./data/${data}/test --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_$i --mode training --early_stop 3 --keep_prob 0.5,0.5,0.5  --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention False --global_experience False --epoch 100 > logs_${data}/${model}_train_$i.log 2>&1 &
    python ./model/train.py --test_data_dir ./data/${data}/test --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_attn_$i --mode training --early_stop 3 --keep_prob 0.5,0.5,0.5  --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience False --epoch 100 > logs_${data}/${model}_attn_train_$i.log 2>&1 &
    python ./model/train.py --test_data_dir ./data/${data}/test --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_attn_nostop_$i --mode training --early_stop 3 --keep_prob 0.5,0.5,0.5  --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience False --co_attention_stop_grad False --epoch 100 > logs_${data}/${model}_attn_nostop_train_$i.log 2>&1 &
    python ./model/train.py --test_data_dir ./data/${data}/test --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_global_$i --mode training --early_stop 3 --keep_prob 0.5,0.5,0.5  --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention False --global_experience True --epoch 100 > logs_${data}/${model}_global_train_$i.log 2>&1 &
    wait_function
    
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/test --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_dml_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience True --epoch 1 --pred_file logs_${data}/${model}_dml_result_$i.txt > logs_${data}/${model}_dml_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/test --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_dml_nostop_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience True --co_attention_stop_grad False --epoch 1 --pred_file logs_${data}/${model}_dml_nostop_result_$i.txt > logs_${data}/${model}_dml_nostop_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/test --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention False --global_experience False --epoch 1 --pred_file logs_${data}/${model}_result_$i.txt > logs_${data}/${model}_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/test --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_attn_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience False --epoch 1 --pred_file logs_${data}/${model}_attn_result_$i.txt > logs_${data}/${model}_attn_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/test --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_attn_nostop_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience False --co_attention_stop_grad False --epoch 1 --pred_file logs_${data}/${model}_attn_nostop_result_$i.txt > logs_${data}/${model}_attn_nostop_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/test --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_global_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention False --global_experience True --epoch 1 --pred_file logs_${data}/${model}_global_result_$i.txt > logs_${data}/${model}_global_test_$i.log 2>&1 & 
    wait_function

    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/train  --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_dml_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience True --epoch 1 --pred_file logs_${data}/${model}_dml_result_train_$i.txt > logs_${data}/${model}_dml_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/train  --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_dml_nostop_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience True --co_attention_stop_grad False --epoch 1 --pred_file logs_${data}/${model}_dml_nostop_result_train_$i.txt > logs_${data}/${model}_dml_nostop_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/train  --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention False --global_experience False --epoch 1 --pred_file logs_${data}/${model}_result_train_$i.txt > logs_${data}/${model}_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/train  --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_attn_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience False --epoch 1 --pred_file logs_${data}/${model}_attn_result_train_$i.txt > logs_${data}/${model}_attn_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/train  --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_attn_nostop_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience False --co_attention_stop_grad False --epoch 1 --pred_file logs_${data}/${model}_attn_nostop_result_train_$i.txt > logs_${data}/${model}_attn_nostop_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/train  --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_global_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention False --global_experience True --epoch 1 --pred_file logs_${data}/${model}_global_result_train_$i.txt > logs_${data}/${model}_global_test_$i.log 2>&1 &
    wait_function

    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/val  --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_dml_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience True --epoch 1 --pred_file logs_${data}/${model}_dml_result_val_$i.txt > logs_${data}/${model}_dml_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/val  --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_dml_nostop_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience True --co_attention_stop_grad False --epoch 1 --pred_file logs_${data}/${model}_dml_nostop_result_val_$i.txt > logs_${data}/${model}_dml_nostop_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/val --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention False --global_experience False --epoch 1 --pred_file logs_${data}/${model}_result_val_$i.txt > logs_${data}/${model}_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/val --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_attn_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience False --epoch 1 --pred_file logs_${data}/${model}_attn_result_val_$i.txt > logs_${data}/${model}_attn_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/val --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_attn_nostop_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention True --global_experience False --co_attention_stop_grad False --epoch 1 --pred_file logs_${data}/${model}_attn_nostop_result_val_$i.txt > logs_${data}/${model}_attn_nostop_test_$i.log 2>&1 &
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/val --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/${model}_global_$i/best --mode pred --model ${model} --global_experience_attn_layer 1 --task_layers 128,80 --co_attention False --global_experience True --epoch 1 --pred_file logs_${data}/${model}_global_result_val_$i.txt > logs_${data}/${model}_global_test_$i.log 2>&1 &
    wait_function
  done  
    
    python ./model/train.py --val_data_dir ./data/${data}/val --test_data_dir ./data/${data}/test  --train_data_dir ./data/${data}/train --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/aitm_$i --mode training --early_stop 3 --keep_prob 0.5,0.5,0.5  --model aitm --epoch 100 > logs_${data}/aitm_train_$i.log 2>&1 &
    wait_function
    python ./model/train.py --val_data_dir ./data/${data}/val --train_data_dir ./data/${data}/train --test_data_dir ./data/${data}/test --uniq_feature_cnt ${feature_cnt} --batch_size 512 --embedding_dim 8 --model_dir ./ckpt_${data}/${data}/aitm_$i/best --mode pred --model aitm --epoch 1 --pred_file logs_${data}/aitm_dml_result_$i.txt > logs_${data}/aitm_test_$i.log 2>&1 &
    wait_function

i=$[$i+1]
done

find logs_${data} -type f -name "*result*" -exec awk '{s=$0};END{print FILENAME,s}' {} \; | sort
done
